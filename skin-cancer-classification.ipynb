{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339},{"sourceId":211953,"sourceType":"modelInstanceVersion","modelInstanceId":180680,"modelId":202933}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"# main libraries\nimport os            # For file and directory management.\nimport pandas as pd  # For handling structured data in DataFrames.\nimport numpy as np   # For numerical computations.\n\n# visualization libraries\nimport matplotlib.pyplot as plt      # For creating visualizations.\nimport seaborn as sns                # For statistical data visualization.\nimport missingno as msno             # To check null values existence.\nfrom matplotlib.colors import LinearSegmentedColormap # To define custom colormaps with smooth color transitions.\nfrom matplotlib.colors import ListedColormap          # For creating colormaps from a list of colors.\nimport warnings            # To manage warning messages.\nfrom PIL import Image      # To handle image loading and manipulation.\n\n# preprocessing libraries\nimport tensorflow as tf    # For building and training the model.\nfrom sklearn.model_selection import train_test_split    # For splitting datasets.\nfrom tensorflow.keras.utils import to_categorical       # To handle categorical data.\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler  # For encoding categorical labels into numeric format.\n\n# Model libraries\nfrom tensorflow.keras.models import Sequential          # For model architecture.\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input, Add, GlobalAveragePooling2D , Concatenate\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau   # To optimize model training\nfrom tensorflow.keras import regularizers         # For adding regularization to prevent overfittin\nimport albumentations as A                        # For image augmentation\nfrom collections import Counter                   # To count the occurrences of labels in the dataset.\nfrom tensorflow.keras.regularizers import l2      # To add L2 weight regularization to layers.\nfrom tensorflow.keras.models import Model\n\n# evaluation libraries\nfrom sklearn.metrics import classification_report , confusion_matrix    # For displaying the model evaluation report\nfrom sklearn.metrics import precision_score, recall_score, f1_score     # To assess the performance of the model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:55:41.215527Z","iopub.execute_input":"2024-12-27T21:55:41.215912Z","iopub.status.idle":"2024-12-27T21:55:41.222661Z","shell.execute_reply.started":"2024-12-27T21:55:41.215886Z","shell.execute_reply":"2024-12-27T21:55:41.22154Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Read Data","metadata":{}},{"cell_type":"code","source":"# Loading the CSV file into a pandas DataFrame.\nimgdata = pd.read_csv('/kaggle/input/skin-cancer-mnist-ham10000/hmnist_28_28_RGB.csv')\nimgdata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:42:30.087827Z","iopub.execute_input":"2024-12-27T21:42:30.088106Z","iopub.status.idle":"2024-12-27T21:42:33.314802Z","shell.execute_reply.started":"2024-12-27T21:42:30.088086Z","shell.execute_reply":"2024-12-27T21:42:33.313898Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Reading the metadata CSV file into a pandas DataFrame.\nfdata = pd.read_csv('/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv')\nfdata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:42:33.752296Z","iopub.execute_input":"2024-12-27T21:42:33.752667Z","iopub.status.idle":"2024-12-27T21:42:33.791702Z","shell.execute_reply.started":"2024-12-27T21:42:33.752637Z","shell.execute_reply":"2024-12-27T21:42:33.790989Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display the frequency of unique values in the 'dx' column of the `fdata` DataFrame.\nprint(fdata['dx'].value_counts())\n\n# Display the frequency of unique values in the 'label' column of the `imgdata` DataFrame.\nprint(imgdata['label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:42:36.455109Z","iopub.execute_input":"2024-12-27T21:42:36.455428Z","iopub.status.idle":"2024-12-27T21:42:36.471059Z","shell.execute_reply.started":"2024-12-27T21:42:36.455404Z","shell.execute_reply":"2024-12-27T21:42:36.470213Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Displaying a concise summary of the dataset.\n# The output includes the following information:\n# 1. Column names and their data types (e.g., int, float, object).\n# 2. Non-null counts for each column, which helps in identifying missing data.\n# 3. Memory usage of the DataFrame.\n# This is for understanding the structure of the dataset and preparing for preprocessing.\nprint(fdata.info())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:42:38.144021Z","iopub.execute_input":"2024-12-27T21:42:38.144318Z","iopub.status.idle":"2024-12-27T21:42:38.164726Z","shell.execute_reply.started":"2024-12-27T21:42:38.144294Z","shell.execute_reply":"2024-12-27T21:42:38.163805Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Comments:**\n 1. The dataset contains 10015 instances.\n 2. There are null values in \"age\" column.\n 3. All columns are Categorical except \"age\" Column.","metadata":{}},{"cell_type":"code","source":"# To check if there is at least one missing value in each column.\n# This outputs a Series where the index corresponds to the column names, and the values are True (if the column has missing data) or False (if it doesn't).\nfdata.isna().any()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:42:39.945377Z","iopub.execute_input":"2024-12-27T21:42:39.945713Z","iopub.status.idle":"2024-12-27T21:42:39.954632Z","shell.execute_reply.started":"2024-12-27T21:42:39.945689Z","shell.execute_reply":"2024-12-27T21:42:39.953927Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a visualizing matrix plot to display the missing data in the dataset.\n# show a heatmap-like representation where:\n# - Each row corresponds to a record (e.g., data point) in the dataset.\n# - Each column represents a feature (e.g., a column in the dataset).\n# - White gaps indicate missing values, making it easy to spot incomplete data.\nmsno.matrix(fdata)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:42:41.524986Z","iopub.execute_input":"2024-12-27T21:42:41.525299Z","iopub.status.idle":"2024-12-27T21:42:42.10994Z","shell.execute_reply.started":"2024-12-27T21:42:41.525275Z","shell.execute_reply":"2024-12-27T21:42:42.108904Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA)","metadata":{}},{"cell_type":"markdown","source":"**We need to answer the following questions:**\n  1. What is the frequency of different lesion types present in the dataset?\n  2. What is the type of the distribution of lesion localization across various anatomical sites?\n  3. What is the proportion of patients according to the gender?\n  4. How are patients distributed according to the age?","metadata":{}},{"cell_type":"code","source":"# - Ignoring FutureWarnings to ensure cleaner outputs during development.\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\ndata = fdata\n# Ensures the use of infinity values is not treated as NaN (Not a Number) when working with datasets.\npd.options.mode.use_inf_as_na = False\n\n# Defining a custom color palette for visualizations:\ncustom_palette = ['#493628', '#AB886D', '#D6C0B3', '#E4E0E1', '#E7E8D8','#CADABF', '#B5CFB7', '#BC9F8B', '#705C53', '#B7B7B7']\n\n# Creating a grid of subplots with a figure size of 15x10 inches:\n# The grid has 2 rows and 2 columns, allowing space for multiple visualizations.\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n# count plot to visualize the distribution of lesion types:\n# - Data: `data` DataFrame, expected to have a column 'dx' containing lesion type labels.\n# - x='dx': Specifies that the x-axis represents lesion types.\n# - ax=axes[0, 0]: Places the plot in the first subplot (top-left corner in this case).\n# - palette=custom_palette: Applies the defined color palette for better aesthetics.\n# - order=data['dx'].value_counts().index: Ensures the lesion types are displayed in descending order of frequency.\nsns.countplot(data=data, x='dx', ax=axes[0, 0],palette=custom_palette[:len(data['dx'].unique())],order=data['dx'].value_counts().index)\n\n#--------------------------------------------------------------------------------------------------------------------------------------------\n\n# Count plot for the count of different lesion localizations in the dataset.\n# - sns.countplot: Creates a bar plot for categorical data.\n# - data=data: Specifies the dataset to be used.\n# - y='localization': Indicates the column representing lesion localization to be plotted along the y-axis.\n# - ax=axes[0, 1]: Specifies the subplot location in a grid of plots (top-right corner in this case).\n# - palette=custom_palette[:len(data['localization'].unique())]: Sets a custom color palette, with unique colors corresponding to the number of unique localization categories.\n# - order=data['localization'].value_counts().index: Orders the categories by their count in descending order.\nsns.countplot(data=data,y='localization',ax=axes[0, 1],palette=custom_palette[:len(data['localization'].unique())],order=data['localization'].value_counts().index)\n\n#--------------------------------------------------------------------------------------------------------------------------------------------\n# This pie chart shows the distribution of gender in the dataset.\ngender_counts = data['sex'].value_counts()     # - data['sex'].value_counts(): Counts the occurrences of each gender in the dataset.\n\n# - labels=gender_counts.index: Sets the pie chart labels as the unique genders.\n# - autopct='%1.1f%%': Displays the percentage distribution with one decimal place.\n# - startangle=90: Starts the pie chart at 90 degrees for better orientation.\n# - colors=custom_palette[:len(gender_counts)]: Uses the custom palette for consistent coloring.\naxes[1, 0].pie(gender_counts,labels=gender_counts.index,autopct='%1.1f%%',startangle=90,colors=custom_palette[:len(gender_counts)])\naxes[1, 0].set_title('Gender Distribution')   # - set_title('Gender Distribution'): Sets the title of the subplot.\n#--------------------------------------------------------------------------------------------------------------------------------------------\n# This histogram is for the distribution of patients' ages.\n# - sns.histplot(): Plots the histogram for numerical data.\n# - data['age']: Specifies the age column from the dataset.\n# - ax=axes[1, 1]: Specifies the subplot location in a grid of plots (bottom-right corner).\n# - kde=True: Adds a Kernel Density Estimate (KDE) curve for a smooth representation of the data distribution.\n# - bins=30: Divides the data range into 30 intervals for the histogram.\n# - color=custom_palette[0]: Sets the bar color to the first color in the custom palette.\nsns.histplot(data['age'],ax=axes[1, 1],kde=True,bins=30,color=custom_palette[0])\n\n#------------------------------------------------------------------------------------------------------------------------------------------\n# Setting titles for subplots to provide context to each visualization:\n# The first subplot (top-left, indexed as [0, 0]) is titled 'Lesion Types'\naxes[0, 0].set_title('Lesion Types')\n\n# The second subplot (top-right, indexed as [0, 1]) is titled 'Localization',\naxes[0, 1].set_title('Localization')\n\n# The third subplot (bottom-right, indexed as [1, 1]) is titled 'Age Distribution',\naxes[1, 1].set_title('Age Distribution')\n\n# Adjusting subplot spacing to ensure that titles and content are displayed without overlap.\nplt.tight_layout()\nplt.show()  # Displaying the plots.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:42:43.939077Z","iopub.execute_input":"2024-12-27T21:42:43.939447Z","iopub.status.idle":"2024-12-27T21:42:44.83059Z","shell.execute_reply.started":"2024-12-27T21:42:43.939412Z","shell.execute_reply":"2024-12-27T21:42:44.829616Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**We need to answer the following question:**\n 1. How does age vary across different lesion types? And are there outliers or not?\n 2. How is the distribution of diagnosis based on gender?\n 3. What is the common diagnosis in each gender?\n 4. How are lesion types distributed across body locations?\n 5. How many are diagnosis methods used for each lesion type? or How are methods more commonly used for specific \n    diagnosis?","metadata":{}},{"cell_type":"code","source":"# Define a custom color palette with of beige and brown for visual consistency in plots.\nbeige_brown_palette = [\"#D2B48C\", \"#C2B280\", \"#8B4513\", \"#6F4F28\", \"#3E2B1B\"]\ndf= data\n# Create a figure with a grid of subplots (2 rows and 2 columns) for multiple visualizations.\n# The figure size is set to (15, 10) for better readability.\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n# Plot 1: Boxplot for the age distribution across different types of skin lesions.\n# - 'dx' represents the diagnosis type (e.g., melanoma, benign, etc.).\n# - 'age' is the dependent variable.\n# - The custom palette is applied for enhancing appearance.\n# - The plot is placed in the first subplot (top-left)\nsns.boxplot(x='dx', y='age', data=df, palette=beige_brown_palette, ax=axes[0, 0])\naxes[0, 0].set_title('Age Distribution by Skin Lesion Type')   # Setting the title for the subplot.\n\n# Plot 2: Countplot to show the frequency of diagnoses by gender.\n# - 'dx' is the x-axis, and gender ('sex') is used as the hue to differentiate groups.\n# - Custom palette is applied, and the plot is placed in the top-right subplot.\nsns.countplot(x='dx', hue='sex', data=df, palette=beige_brown_palette, ax=axes[0, 1])\naxes[0, 1].set_title('Diagnosis by Gender')  # Set the title for the plot.\naxes[0, 1].set_xticklabels(axes[0, 1].get_xticklabels(), rotation=45)  # Rotate x-axis labels for better visibility.\n\n# Plot 3: Heatmap to show the relationship between lesion localization and diagnosis type.\n# - A crosstab table is created to aggregate the data, and annotations are added to the heatmap for clarity.\n# - A custom colormap is derived from the beige-brown palette.\n# - The plot is placed in the bottom-left subplot.\ncmap = ListedColormap(beige_brown_palette)  # Create a colormap for the heatmap.\nsns.heatmap(pd.crosstab(df['localization'], df['dx']), annot=True, fmt=\"d\", cmap=cmap, ax=axes[1, 0])\naxes[1, 0].set_title('Localization vs Diagnosis')  # Set the title for the plot.\n\n# Plot 4: Grouped bar chart to show the count of diagnosis types vs diagnosis methods.\n# - A pivot table is created to summarize the data for plotting.\n# - 'dx' is used as the x-axis, and the pivot table values are grouped and plotted.\n# - The custom colormap is applied, and the plot is placed in the bottom-right subplot.\npivot = df.pivot_table(index='dx', columns='dx_type', aggfunc='size', fill_value=0)  # Create a pivot table.\npivot = pivot.reset_index()  # Reset the index for compatibility with plotting.\n\npivot.plot(x='dx', kind='bar', figsize=(12, 8), colormap=cmap, ax=axes[1, 1])   # Plot as a bar chart.\naxes[1, 1].set_title('Grouped Bar Chart: Diagnosis Type vs Diagnosis Method')   # Set the title for the plot.\naxes[1, 1].set_ylabel('Count')  # Label the y-axis.\naxes[1, 1].set_xlabel('Diagnosis Type (dx)')   # Label the x-axis.\naxes[1, 1].set_xticklabels(axes[1, 1].get_xticklabels(), rotation=45)  # Rotate x-axis labels for better visibility.\n\nplt.tight_layout()  # Adjust the layout to prevent overlapping of subplots.\nplt.show()  # Display all the plots.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:42:47.674682Z","iopub.execute_input":"2024-12-27T21:42:47.674984Z","iopub.status.idle":"2024-12-27T21:42:49.318874Z","shell.execute_reply.started":"2024-12-27T21:42:47.674961Z","shell.execute_reply":"2024-12-27T21:42:49.317954Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Displaying five randomly selected images from each diagnosis.","metadata":{}},{"cell_type":"code","source":"# Displaying summary statistics for the DataFrame 'fdata', including count, mean, standard deviation, min, and max for each numerical column\nfdata.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:42:49.857964Z","iopub.execute_input":"2024-12-27T21:42:49.858333Z","iopub.status.idle":"2024-12-27T21:42:49.869265Z","shell.execute_reply.started":"2024-12-27T21:42:49.858291Z","shell.execute_reply":"2024-12-27T21:42:49.868335Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Defining paths to the two parts of the image dataset and the metadata file.\nimages_path_1 = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1/'\nimages_path_2 = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2/'\nmetadata_path = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv'\n\ndf = pd.read_csv(metadata_path)\n\n# Adding a new column 'image_path' to the DataFrame that contains the full path to the corresponding image file by:\n# - Checking if the image exists in 'images_path_1'.\n# - If not, it assigns the path from 'images_path_2'.\ndf['image_path'] = df['image_id'].apply(\n    lambda x: os.path.join(images_path_1, x + '.jpg') if os.path.exists(os.path.join(images_path_1, x + '.jpg')) \n    else os.path.join(images_path_2, x + '.jpg')\n)\n\n# Extracting the unique categories (diagnosis labels) from the dataset.\n# The 'dx' column in the metadata contains the labels.\ncategories = df['dx'].unique()\nnum_samples = 5  # Defining the number of sample images to display per category.\n# Creating a grid of subplots to display sample images from each category.\n# The number of rows is equal to the number of categories, and each row has 'num_samples' images.\nfig, axes = plt.subplots(len(categories), num_samples, figsize=(15, 3 * len(categories)))\n\n# Iterating over each category to display sample images.\nfor i, category in enumerate(categories):\n    # Randomly sampling 'num_samples' images from the current category.\n    category_images = df[df['dx'] == category].sample(num_samples)\n\n    # Iterating over the sampled images to display them in the corresponding subplot.\n    for j, image_path in enumerate(category_images['image_path']):        \n        img = Image.open(image_path)   # Loading the image from the file path.\n        axes[i, j].imshow(img)         # Displaying the image in the corresponding subplot.\n        axes[i, j].set_title(category) # Setting the title of the subplot to the category label.\n        axes[i, j].axis('off')         # Removing axis ticks for a cleaner display.\n\nplt.tight_layout()   # Adjusting the layout to prevent overlapping of subplots.\nplt.show()           # Displaying the grid of images.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:42:52.753668Z","iopub.execute_input":"2024-12-27T21:42:52.75396Z","iopub.status.idle":"2024-12-27T21:43:07.978881Z","shell.execute_reply.started":"2024-12-27T21:42:52.753938Z","shell.execute_reply":"2024-12-27T21:43:07.977581Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Displaying five randomly selected images from the dataset, categorized by gender.","metadata":{}},{"cell_type":"code","source":"# Filtering the dataset to separate images based on the 'sex' column.\n# The variable 'males' contains rows where the 'sex' column is 'male'.\n# The variable 'females' contains rows where the 'sex' column is 'female'.\nmales = df[df['sex'] == 'male'] \nfemales = df[df['sex'] == 'female']  \n\n# Visualizing 5 images of male subjects from the dataset.\nplt.figure(figsize=(15, 5)) # Setting the figure size for better visualization.\n\n# Looping through the first 5 male entries.\nfor i in range(5):  \n    image_path = males.iloc[i]['image_path']  # Extracting the image path for each male subject.\n    image = Image.open(image_path)   # Opening the image using PIL Library. \n    plt.subplot(1, 5, i + 1)         # Creating a subplot for each image (1 row, 5 columns).\n    plt.imshow(image)  # Displaying the image.\n    plt.axis('off')    # Hiding the axes for a cleaner look.\n    plt.title(f'Male: {males.iloc[i][\"dx\"]}') # Setting the title with the diagnosis ('dx') for each image.\nplt.show()    # Displaying the figure.\n\n# Visualizing 5 images of female subjects from the dataset.\nplt.figure(figsize=(15, 5))  # Setting the figure size for better visualization.\nfor i in range(5):   # Looping through the first 5 female entries.\n    image_path = females.iloc[i]['image_path']    # Extracting the image path for each female subject.\n    image = Image.open(image_path)  # Opening the image using PIL Library.\n    plt.subplot(1, 5, i + 1)   # Creating a subplot for each image (1 row, 5 columns).\n    plt.imshow(image)   # Displaying the image.\n    plt.axis('off')     # Hiding the axes for a cleaner look.\n    plt.title(f'Female: {females.iloc[i][\"dx\"]}') # Setting the title with the diagnosis ('dx') for each image.\nplt.show()    # Displaying the figure.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:07.980493Z","iopub.execute_input":"2024-12-27T21:43:07.98094Z","iopub.status.idle":"2024-12-27T21:43:09.300947Z","shell.execute_reply.started":"2024-12-27T21:43:07.980895Z","shell.execute_reply":"2024-12-27T21:43:09.299886Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualizing the class distribution using a pie chart\n# Create a figure with a size of 6x6 inches.\nplt.figure(figsize=(6, 6))\n\n# Plot a pie chart using the counts of each label from the 'label' column in the imgdata DataFrame.\n# Display percentages on the chart with one decimal point for each slice.\nplt.pie(imgdata['label'].value_counts().values , labels=imgdata['label'].value_counts().index ,autopct='%1.1f%%')\nplt.title('Classes pie chart')    # Add a title to the chart: \"Classes pie chart\".\nplt.show()   # Show the chart","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:09.302292Z","iopub.execute_input":"2024-12-27T21:43:09.302647Z","iopub.status.idle":"2024-12-27T21:43:09.455952Z","shell.execute_reply.started":"2024-12-27T21:43:09.302619Z","shell.execute_reply":"2024-12-27T21:43:09.45389Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# drop unnececcary columns\nfdata = fdata.drop(columns = ['lesion_id' , 'image_id' ,'dx'] , axis =1)\nfdata.head()    # Display the first rows","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:14.371545Z","iopub.execute_input":"2024-12-27T21:43:14.371852Z","iopub.status.idle":"2024-12-27T21:43:14.381892Z","shell.execute_reply.started":"2024-12-27T21:43:14.37183Z","shell.execute_reply":"2024-12-27T21:43:14.380914Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# fill nulls in age columns using its mean value\nfdata['age'] = fdata['age'].fillna(51)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:16.070408Z","iopub.execute_input":"2024-12-27T21:43:16.070769Z","iopub.status.idle":"2024-12-27T21:43:16.075363Z","shell.execute_reply.started":"2024-12-27T21:43:16.070739Z","shell.execute_reply":"2024-12-27T21:43:16.074463Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Split","metadata":{}},{"cell_type":"code","source":"# split to features & target\ny = imgdata['label']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:17.741848Z","iopub.execute_input":"2024-12-27T21:43:17.742154Z","iopub.status.idle":"2024-12-27T21:43:17.745696Z","shell.execute_reply.started":"2024-12-27T21:43:17.742124Z","shell.execute_reply":"2024-12-27T21:43:17.744812Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# drop target column to isolate the feature data\nimgs = imgdata.drop(columns = ['label'] , axis =1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:17.997433Z","iopub.execute_input":"2024-12-27T21:43:17.997769Z","iopub.status.idle":"2024-12-27T21:43:18.057031Z","shell.execute_reply.started":"2024-12-27T21:43:17.997742Z","shell.execute_reply":"2024-12-27T21:43:18.056297Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# concatenate pixels value with row data\ndata = pd.concat([fdata, pd.DataFrame(imgs)], axis=1)\ndata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:19.927585Z","iopub.execute_input":"2024-12-27T21:43:19.927879Z","iopub.status.idle":"2024-12-27T21:43:20.011987Z","shell.execute_reply.started":"2024-12-27T21:43:19.927857Z","shell.execute_reply":"2024-12-27T21:43:20.011161Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split the dataset into 80% training data and 20% testing data.\nx_trainall, x_testall, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=42, stratify=y)\n\n# Split the training data into 80% training data and 20% validation sets.\nx_trainall, x_valall, y_train, y_val = train_test_split(x_trainall, y_train, test_size=0.2, random_state=42, stratify=y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:22.06057Z","iopub.execute_input":"2024-12-27T21:43:22.060868Z","iopub.status.idle":"2024-12-27T21:43:22.2519Z","shell.execute_reply.started":"2024-12-27T21:43:22.060846Z","shell.execute_reply":"2024-12-27T21:43:22.251207Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display the column names of the x_trainall DataFrame\nx_trainall.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:22.293279Z","iopub.execute_input":"2024-12-27T21:43:22.293559Z","iopub.status.idle":"2024-12-27T21:43:22.299042Z","shell.execute_reply.started":"2024-12-27T21:43:22.293498Z","shell.execute_reply":"2024-12-27T21:43:22.298331Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display class distribution after splitting the dataset\nprint(\"\\nClass distribution after splitting:\")\n\n# Print the distribution of classes in the training set\nprint(\"Training set distribution:\")\nprint(y_train.value_counts().sort_index())\n\n# Print the distribution of classes in the validation set\nprint(\"\\nValidation set distribution:\")\nprint(y_val.value_counts().sort_index())\n\n# Print the distribution of classes in the test set\nprint(\"\\nTest set distribution:\")\nprint(y_test.value_counts().sort_index())\n\n# Display the number of samples in each dataset (training, validation, test)\nprint(\"\\nNumber of samples in each set:\")  \nprint(f\"Training: {len(y_train)}\")         # Number of samples in the training set\nprint(f\"Validation: {len(y_val)}\")         # Number of samples in the validation set\nprint(f\"Test: {len(y_test)}\")              # Number of samples in the test set","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:24.084165Z","iopub.execute_input":"2024-12-27T21:43:24.084457Z","iopub.status.idle":"2024-12-27T21:43:24.096174Z","shell.execute_reply.started":"2024-12-27T21:43:24.084435Z","shell.execute_reply":"2024-12-27T21:43:24.095231Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display the column names of the x_trainall DataFrame\nx_trainall.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:26.891938Z","iopub.execute_input":"2024-12-27T21:43:26.892238Z","iopub.status.idle":"2024-12-27T21:43:26.897691Z","shell.execute_reply.started":"2024-12-27T21:43:26.892215Z","shell.execute_reply":"2024-12-27T21:43:26.896924Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# split into images and row data for training dataset\n\n# Select specific columns from the dataset to create the 'x_train_tabilar' dataframe\nx_train_tabilar = x_trainall[['dx_type', 'age', 'sex', 'localization']]\n\n# Drop the selected columns from the original dataset to create 'x_train_imgs' containing only image data\nx_train_imgs = x_trainall.drop(columns= ['dx_type', 'age', 'sex', 'localization'] , axis =1)\nx_train_tabilar","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:27.184972Z","iopub.execute_input":"2024-12-27T21:43:27.185296Z","iopub.status.idle":"2024-12-27T21:43:27.231531Z","shell.execute_reply.started":"2024-12-27T21:43:27.185271Z","shell.execute_reply":"2024-12-27T21:43:27.230744Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split into image and tabular data for validation test\n\n# Extracting the tabular features (dx_type, age, sex, localization) from validation dataset\nX_tabular_val = x_valall[['dx_type','age', 'sex' , 'localization']]\n\n# Extracting the image features by removing the tabular columns from validation dataset\nX_images_val = x_valall.drop(['dx_type','age', 'sex' , 'localization'], axis=1).values\n\n# Extracting the target labels for validation set\ny_train_val = y_val.values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:29.838761Z","iopub.execute_input":"2024-12-27T21:43:29.839048Z","iopub.status.idle":"2024-12-27T21:43:29.854948Z","shell.execute_reply.started":"2024-12-27T21:43:29.839026Z","shell.execute_reply":"2024-12-27T21:43:29.854111Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split into image and tabular data for test dataset\n\n# Extracting the tabular features (dx_type, age, sex, localization) from test dataset\nX_tabular_test = x_testall[['dx_type','age', 'sex' , 'localization']]\n\n# Extracting the image features by removing the tabular columns from testdataset\nX_images_test = x_testall.drop(['dx_type','age', 'sex' , 'localization'], axis=1).values\n\n# Extracting the target labels for test set\ny_train_test = y_test.values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:30.08865Z","iopub.execute_input":"2024-12-27T21:43:30.088934Z","iopub.status.idle":"2024-12-27T21:43:30.106957Z","shell.execute_reply.started":"2024-12-27T21:43:30.088912Z","shell.execute_reply":"2024-12-27T21:43:30.106067Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_train_imgs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:31.761642Z","iopub.execute_input":"2024-12-27T21:43:31.761941Z","iopub.status.idle":"2024-12-27T21:43:31.777819Z","shell.execute_reply.started":"2024-12-27T21:43:31.761919Z","shell.execute_reply":"2024-12-27T21:43:31.776933Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# show shape of images data\nx_train_imgs.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:33.810482Z","iopub.execute_input":"2024-12-27T21:43:33.810825Z","iopub.status.idle":"2024-12-27T21:43:33.815583Z","shell.execute_reply.started":"2024-12-27T21:43:33.810796Z","shell.execute_reply":"2024-12-27T21:43:33.814838Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Adding the target column to the dataset\ntabular_data = x_train_tabilar\ntabular_data['class'] = y_train.values\ntabular_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:34.090287Z","iopub.execute_input":"2024-12-27T21:43:34.090582Z","iopub.status.idle":"2024-12-27T21:43:34.103731Z","shell.execute_reply.started":"2024-12-27T21:43:34.090557Z","shell.execute_reply":"2024-12-27T21:43:34.102848Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ensure the similarity of the index\ntabular_data.index == x_train_imgs.index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:37.188219Z","iopub.execute_input":"2024-12-27T21:43:37.188541Z","iopub.status.idle":"2024-12-27T21:43:37.193976Z","shell.execute_reply.started":"2024-12-27T21:43:37.188494Z","shell.execute_reply":"2024-12-27T21:43:37.193199Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# reset index of two datasets\ntabular_data = tabular_data.reset_index(drop=True)\nx_train_imgs = x_train_imgs.reset_index(drop = True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:37.464269Z","iopub.execute_input":"2024-12-27T21:43:37.464609Z","iopub.status.idle":"2024-12-27T21:43:37.512436Z","shell.execute_reply.started":"2024-12-27T21:43:37.464582Z","shell.execute_reply":"2024-12-27T21:43:37.511757Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_train_imgs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:38.491016Z","iopub.execute_input":"2024-12-27T21:43:38.491312Z","iopub.status.idle":"2024-12-27T21:43:38.507093Z","shell.execute_reply.started":"2024-12-27T21:43:38.491287Z","shell.execute_reply":"2024-12-27T21:43:38.5063Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check the shape of the tabular_data\ntabular_data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:40.529311Z","iopub.execute_input":"2024-12-27T21:43:40.529648Z","iopub.status.idle":"2024-12-27T21:43:40.534397Z","shell.execute_reply.started":"2024-12-27T21:43:40.529623Z","shell.execute_reply":"2024-12-27T21:43:40.533597Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check the shape of the x_train_imgs\nx_train_imgs.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:40.751907Z","iopub.execute_input":"2024-12-27T21:43:40.752214Z","iopub.status.idle":"2024-12-27T21:43:40.757452Z","shell.execute_reply.started":"2024-12-27T21:43:40.752187Z","shell.execute_reply":"2024-12-27T21:43:40.756673Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Handle Unbalanced","metadata":{}},{"cell_type":"code","source":"# oversampler = RandomOverSampler(random_state=42)\n\n\n# # Apply oversampling\n# x_train_resampled, y_train_resampled = oversampler.fit_resample(x_trainall, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:42.524065Z","iopub.execute_input":"2024-12-27T21:43:42.524384Z","iopub.status.idle":"2024-12-27T21:43:42.527726Z","shell.execute_reply.started":"2024-12-27T21:43:42.524355Z","shell.execute_reply":"2024-12-27T21:43:42.526915Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def reshape_to_image(flat_data):\n    \"\"\"\n    Reshapes flat data into image format (height, width, channels).\n\n    Parameters:\n    flat_data: numpy array or pandas DataFrame\n        The flattened data to be reshaped.\n\n    Returns:\n    numpy array\n        Reshaped image data.\n    \"\"\"\n    if isinstance(flat_data, pd.DataFrame):          # Check if the input data is a Pandas DataFrame\n        flat_data = flat_data.values                 # Convert the DataFrame to a NumPy array\n    return flat_data.reshape(-1, 28, 28, 3)          # Reshape the data to have dimensions (n_samples, 28, 28, 3)\n\n\n# A function to reshape image data back to flat format\ndef reshape_to_flat(image_data):\n    \"\"\"\n    Reshapes image data into flat format.\n\n    Parameters:\n    image_data: numpy array\n        The image data to be reshaped.\n\n    Returns:\n    numpy array\n        Flattened image data.\n    \"\"\"\n    return image_data.reshape(image_data.shape[0], -1)    # Reshaping the image_data array to flatten each image\n\n\n# A function to create an augmentation pipeline\ndef create_augmentation_pipeline():\n    \"\"\"\n    Creates a data augmentation pipeline using albumentations.\n\n    Returns:\n    albumentations.Compose\n        The composed transformation pipeline.\n    \"\"\"  \n    # Define the sequence of transformations\n    # These transformations help enhance the dataset by generating diverse variations of images To improve generalization.\n    transform = A.Compose([\n        A.Rotate(limit=30, p=0.7),      # Randomly rotates the image within +30 or -30 degrees with a 70% probability.\n        A.HorizontalFlip(p=0.5),        # Flips the image horizontally with a 50% probability.\n        A.VerticalFlip(p=0.5),          # Flips the image vertically with a 50% probability.\n        A.OneOf([                   # Randomly applies one of the noise addition techniques with a 20% probability.\n            A.GaussNoise(p=1),          # Adds random Gaussian noise to the image.\n            A.MultiplicativeNoise(p=1),   # Adds random multiplicative noise to the image.\n        ], p=0.2),\n        A.OneOf([                   # Randomly applies one of the blurring techniques with a 20% probability.\n            A.MotionBlur(p=1),                 # Introduces motion blur to simulate the effect of movement.\n            A.MedianBlur(blur_limit=3, p=1),   # Applies a median blur with a kernel size of up to 3.\n            A.GaussianBlur(blur_limit=3, p=1),   # Applies a Gaussian blur with a kernel size of up to 3.\n        ], p=0.2),\n        A.ColorJitter(       # Adjusts image brightness, contrast, saturation, and hue within specified limits\n                             # to simulate varying lighting conditions with a 70% probability.\n            brightness=0.2,         # Adjusts brightness by +20% or -20%.\n            contrast=0.2,           # Adjusts contrast by +20% or -20%.\n            saturation=0.2,         # Adjusts saturation by +20% or -20%.\n            hue=0.1,                # Adjusts hue by +10% or -10%.\n            p=0.7\n        ),\n    ])\n    return transform     # Returns the composed augmentation pipeline.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:43.525837Z","iopub.execute_input":"2024-12-27T21:43:43.526121Z","iopub.status.idle":"2024-12-27T21:43:43.532598Z","shell.execute_reply.started":"2024-12-27T21:43:43.526098Z","shell.execute_reply":"2024-12-27T21:43:43.531693Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def augment_minority_classes(x_train, x_train_tabilar, y_train, target_samples=None):\n \n    \"\"\"\n    Augments minority classes in the training dataset to balance class distributions.\n\n    This function performs data augmentation on image data associated with minority classes \n    while preserving tabular data alignment. It increases the number of samples for each \n    class to match the size of the largest class or a specified target number of samples.\n\n    Parameters:\n    ----------\n    x_train : pandas.DataFrame or numpy.ndarray\n        The input training data containing image features, either as a flat DataFrame \n        or a NumPy array.\n    \n    x_train_tabilar : pandas.DataFrame\n        The tabular data associated with each image sample.\n    \n    y_train : pandas.Series or numpy.ndarray\n        The target labels for the training data.\n\n    target_samples : int, optional\n        The desired number of samples for each class. If not provided, the size of the \n        largest class is used.\n\n    Returns:\n    -------\n    tuple\n        A tuple containing:\n        - x_aug (pandas.DataFrame): Augmented image data.\n        - x_aug_row (pandas.DataFrame): Augmented tabular data.\n        - y_aug (pandas.Series): Updated target labels.\n\"\"\"\n    if isinstance(y_train, pd.Series):\n        y_train = y_train.values\n        \n    # Count the number of samples for each class.\n    class_counts = Counter(y_train)\n\n    # If target_samples is not provided, set it to the number of samples in the largest class.\n    if target_samples is None:       \n        target_samples = max(class_counts.values())\n        \n    # Convert the training data into image format if needed.\n    x_images = reshape_to_image(x_train)\n    \n    # Scale pixel values to 0-255 range if they are normalized (values <= 1.0).\n    if x_images.max() <= 1.0:\n        x_images = (x_images * 255).astype(np.uint8)\n        \n    # call the data augmentation pipeline to apply the required transformation.\n    transform = create_augmentation_pipeline()\n\n    # Initialize lists to store augmented images and their corresponding labels and row data.\n    augmented_images = []\n    augmented_rows = []\n    augmented_labels = []\n\n    for class_label in class_counts:    # Iterate over each class in the dataset.\n        \n        # Initialize lists to store augmented images and their corresponding labels.\n        class_indices = np.where(y_train == class_label)[0]\n        class_images = x_images[class_indices]\n        class_rows = x_train_tabilar.iloc[class_indices]  # Use .iloc to preserve positional indexing\n\n        # Determine the number of samples for the current class.\n        n_samples = len(class_images)\n        if n_samples < target_samples:        # If the class is underrepresented, generate additional samples by augmentation.\n            n_augment = target_samples - n_samples         # Number of new samples to create.\n\n            # Perform data augmentation until the desired number of samples is reached.\n            for i in range(n_augment):\n                idx = i % n_samples\n                image = class_images[idx].astype(np.uint8)\n\n                # Apply the augmentation pipeline to the current image.\n                augmented = transform(image=image)\n                augmented_image = augmented['image']\n\n                # Add the augmented image and corresponding label to the lists.\n                augmented_images.append(augmented_image)\n                augmented_labels.append(class_label)\n\n                # Append tabular data as a proper row (ensure it's a 1D array, not 2D or nested)\n                augmented_rows.append(class_rows.iloc[idx].to_numpy())\n\n    # Combine original and augmented data, if any new samples were generated.\n    if augmented_images:\n        \n        # Convert augmented images and rows to DataFrames\n        augmented_images_df = pd.DataFrame(\n            reshape_to_flat(np.array(augmented_images)), \n            columns=x_train.columns if isinstance(x_train, pd.DataFrame) else None\n        )\n        # Ensure whether it is a DataFrame.\n        augmented_rows_df = pd.DataFrame(\n            augmented_rows, \n            columns=x_train_tabilar.columns if isinstance(x_train_tabilar, pd.DataFrame) else None\n        )\n        augmented_labels_series = pd.Series(augmented_labels, name=\"label\")\n\n        # Concatenate the original and augmented data\n        x_aug = pd.concat([x_train, augmented_images_df], ignore_index=True)\n        x_aug_row = pd.concat([x_train_tabilar, augmented_rows_df], ignore_index=True)\n        y_aug = pd.concat([pd.Series(y_train, name=\"label\"), augmented_labels_series], ignore_index=True)\n\n        return x_aug, x_aug_row, y_aug\n\n    return x_train, x_train_tabilar, y_train     \n\n# Apply augmentation to the training dataset.\nx_train_aug,x_aug_row, y_train_aug = augment_minority_classes(x_train_imgs,tabular_data, y_train)\n\nprint(\"Before:\")\nprint(Counter(y_train))\nprint(\"\\nAfter:\")\nprint(Counter(y_train_aug))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:43:46.785095Z","iopub.execute_input":"2024-12-27T21:43:46.78541Z","iopub.status.idle":"2024-12-27T21:44:04.675641Z","shell.execute_reply.started":"2024-12-27T21:43:46.785383Z","shell.execute_reply":"2024-12-27T21:44:04.674882Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# show row data after augmentation\nx_aug_row","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:44:04.676666Z","iopub.execute_input":"2024-12-27T21:44:04.676973Z","iopub.status.idle":"2024-12-27T21:44:04.687594Z","shell.execute_reply.started":"2024-12-27T21:44:04.676946Z","shell.execute_reply":"2024-12-27T21:44:04.68685Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# show image data after augmentation\nx_train_aug","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:44:04.688745Z","iopub.execute_input":"2024-12-27T21:44:04.688993Z","iopub.status.idle":"2024-12-27T21:44:04.715603Z","shell.execute_reply.started":"2024-12-27T21:44:04.688973Z","shell.execute_reply":"2024-12-27T21:44:04.714914Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualizing the class distribution after augmentation\n# Create a figure with a size of 6x6 inches.\nplt.figure(figsize=(6, 6))\n\n# Plot a pie chart using the counts of each label.\n# Display percentages on the chart with one decimal point for each slice.\nplt.pie(x_aug_row['class'].value_counts().values , labels=x_aug_row['class'].value_counts().index ,autopct='%1.1f%%')\nplt.title('Classes pie chart')     # Add a title to the chart: \"Classes pie chart\".\nplt.show()     # show the chart","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:44:04.716438Z","iopub.execute_input":"2024-12-27T21:44:04.716678Z","iopub.status.idle":"2024-12-27T21:44:04.850019Z","shell.execute_reply.started":"2024-12-27T21:44:04.716658Z","shell.execute_reply":"2024-12-27T21:44:04.848632Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Normalize pixel values\n# Normalizing the pixel values of the training dataset (x_train_aug) by dividing by 255.0 to improve model convergence.\nx_train_aug = x_train_aug / 255.0\n\n# Normalizing the validation dataset (X_images_val) by dividing by 255.0.\nX_images_val = X_images_val / 255.0\n\n# Normalizing the test dataset (X_images_test) by dividing by 255.0.\nX_images_test = X_images_test / 255.0\n\n# Reshaping the augmented training data (x_train_aug) into a 4D array with shape (samples, height, width, channels),\n# where -1 indicates an automatic adjustment to match the number of samples, 28x28 is the image size, \n# and 3 represents the color channels (RGB).\nimage_shape = (28, 28, 3)\n\nx_train_aug = x_train_aug.to_numpy()  # Convert to NumPy array\nx_train_aug_reshaped = x_train_aug.reshape(-1, *image_shape) # Reshape images\n\n\nX_images_val_reshaped = X_images_val.reshape(-1, *image_shape)\nX_images_test_reshaped = X_images_test.reshape(-1, *image_shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:44:07.230731Z","iopub.execute_input":"2024-12-27T21:44:07.231031Z","iopub.status.idle":"2024-12-27T21:44:07.367524Z","shell.execute_reply.started":"2024-12-27T21:44:07.231007Z","shell.execute_reply":"2024-12-27T21:44:07.366812Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Encode gender column\nX_tabular_resampled = x_aug_row \nlbl = LabelEncoder()  # create object from encoding class\nX_tabular_resampled['sex_encoded'] = lbl.fit_transform(X_tabular_resampled['sex'])  # apply on train data\nX_tabular_val['sex_encoded'] = lbl.transform(X_tabular_val['sex'])     # apply on validation data\nX_tabular_test['sex_encoded'] = lbl.transform(X_tabular_test['sex'])   # apply on test data\n\n# Encode dx_type column\nX_tabular_resampled['dx_type_encoded'] = lbl.fit_transform(X_tabular_resampled['dx_type'])  # apply on train data\nX_tabular_val['dx_type_encoded'] = lbl.transform(X_tabular_val['dx_type'])      # apply on validation data\nX_tabular_test['dx_type_encoded'] = lbl.transform(X_tabular_test['dx_type'])    # apply on test data\n\n# Encode localization column\nX_tabular_resampled['localization_encoded'] = lbl.fit_transform(X_tabular_resampled['localization'])  # apply on train data\nX_tabular_val['localization_encoded'] = lbl.transform(X_tabular_val['localization'])      # apply on validation data\nX_tabular_test['localization_encoded'] = lbl.transform(X_tabular_test['localization'])    # apply on test data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:44:10.890839Z","iopub.execute_input":"2024-12-27T21:44:10.891127Z","iopub.status.idle":"2024-12-27T21:44:10.915528Z","shell.execute_reply.started":"2024-12-27T21:44:10.891104Z","shell.execute_reply":"2024-12-27T21:44:10.914665Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Scale age column using minmaxscaler\nscaler = MinMaxScaler()  # create object \nX_tabular_resampled['age_scaled'] = scaler.fit_transform(X_tabular_resampled[['age']])  # apply on train data\nX_tabular_val['age_scaled'] = scaler.transform(X_tabular_val[['age']])                # apply on validation data\nX_tabular_test['age_scaled'] = scaler.transform(X_tabular_test[['age']])            # apply on test data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:44:13.43196Z","iopub.execute_input":"2024-12-27T21:44:13.432308Z","iopub.status.idle":"2024-12-27T21:44:13.445612Z","shell.execute_reply.started":"2024-12-27T21:44:13.432277Z","shell.execute_reply":"2024-12-27T21:44:13.444733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare tabular data by selecting relevant features from the resampled data\nX_tabular_prepared_train = X_tabular_resampled[['age_scaled', 'localization_encoded','sex_encoded' , 'dx_type_encoded']].values\nX_tabular_prepared_val = X_tabular_val[['age_scaled', 'localization_encoded','sex_encoded' ,'dx_type_encoded']].values\nX_tabular_prepared_test = X_tabular_test[['age_scaled', 'localization_encoded','sex_encoded' ,'dx_type_encoded']].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:44:15.694071Z","iopub.execute_input":"2024-12-27T21:44:15.694363Z","iopub.status.idle":"2024-12-27T21:44:15.702166Z","shell.execute_reply.started":"2024-12-27T21:44:15.69434Z","shell.execute_reply":"2024-12-27T21:44:15.701328Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# check its shape\nX_tabular_prepared_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:44:21.13188Z","iopub.execute_input":"2024-12-27T21:44:21.132199Z","iopub.status.idle":"2024-12-27T21:44:21.137001Z","shell.execute_reply.started":"2024-12-27T21:44:21.13217Z","shell.execute_reply":"2024-12-27T21:44:21.136337Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# Image input branch with Convolutional layers\nimage_input = Input(shape= (28,28,3), name=\"image_input\")\n\n# Add convolutional and pooling layers\nx = Conv2D(32, (3, 3), activation='relu', padding='same')(image_input)  # First Conv2D layer\nx = MaxPooling2D((2, 2))(x)  # First pooling layer\n\nx = Conv2D(64, (3, 3), activation='relu', padding='same')(x)  # Second Conv2D layer\nx = MaxPooling2D((2, 2))(x)  # Second pooling layer\n\nx = Flatten()(x)  # Flatten the features for the dense layers\nx = Dense(64, activation='relu')(x)\nx = Dense(128, activation='relu')(x)  # Dense layer after flattening\n\n# Tabular input branch\ntabular_input = Input(shape=(4,), name=\"tabular_input\")  # Adjust for 4 features\ny = Dense(16, activation='relu')(tabular_input)  # Dense layer for tabular input\n\n# Combine both branches\ncombined = Concatenate()([x, y])\nz = Dense(128, activation='relu')(combined)  # Dense layer after combining\nz = Dense(64, activation='softmax')(z)\nz = Dense(32, activation='softmax')(z)\nz = Dense(16, activation='softmax')(z)\nz = Dense(7, activation='softmax')(z)  # Output layer for classification\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T15:04:38.330792Z","iopub.execute_input":"2024-12-27T15:04:38.33118Z","iopub.status.idle":"2024-12-27T15:04:39.057763Z","shell.execute_reply.started":"2024-12-27T15:04:38.331149Z","shell.execute_reply":"2024-12-27T15:04:39.057104Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create the model\nmodel = Model(inputs=[image_input, tabular_input], outputs=z)\n\n# Compile the model with the Adam optimizer and sparse categorical crossentropy loss function\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Display model summary\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T15:04:40.781137Z","iopub.execute_input":"2024-12-27T15:04:40.781435Z","iopub.status.idle":"2024-12-27T15:04:40.819189Z","shell.execute_reply.started":"2024-12-27T15:04:40.781412Z","shell.execute_reply":"2024-12-27T15:04:40.818363Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# List of callbacks to pass to the model during training\n\ncallbacks = [                     # EarlyStopping callback to stop training when validation loss stops improving\n    EarlyStopping(\n        monitor='val_accuracy',        # Monitor validation loss for early stopping\n        patience=15,                   # Number of epochs to wait for improvement\n        restore_best_weights=True,     # Restore the model weights from the best epoch\n        verbose=1\n    ),\n    ModelCheckpoint(          # ModelCheckpoint callback to save the model with the best validation loss\n        'best_model.keras',        # Filepath to save the best model\n        monitor='val_accuracy',    # Monitor the validation loss metric\n        save_best_only=True,       # Save only the best model based on validation loss\n        verbose=1,                 \n        mode='max'              # Since we're monitoring accuracy\n    ),\n    ReduceLROnPlateau(     # ReduceLROnPlateau: Reduces the learning rate by a factor of 0.5 if the validation loss does not improve for 5 epochs.\n        monitor='val_loss',\n        factor=0.5,             # Less aggressive reduction\n        patience=5,\n        min_lr=1e-6,\n        verbose=1\n    )\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T17:14:46.25113Z","iopub.execute_input":"2024-12-27T17:14:46.251434Z","iopub.status.idle":"2024-12-27T17:14:46.256044Z","shell.execute_reply.started":"2024-12-27T17:14:46.251411Z","shell.execute_reply":"2024-12-27T17:14:46.254921Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train the model\nhistory = model.fit(\n    [x_train_aug_reshaped, X_tabular_prepared_train], y_train_aug,\n    validation_data=([X_images_val_reshaped , X_tabular_prepared_val], y_val),\n    epochs=50,\n    batch_size=32,\n    callbacks = callbacks\n\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T15:07:33.807033Z","iopub.execute_input":"2024-12-27T15:07:33.807336Z","iopub.status.idle":"2024-12-27T15:09:49.663153Z","shell.execute_reply.started":"2024-12-27T15:07:33.807314Z","shell.execute_reply":"2024-12-27T15:09:49.662493Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"# print model accurices on train & validation & test\ntrain_score = model.evaluate([x_train_aug_reshaped, X_tabular_prepared_train], y_train_aug, verbose=1)\nval_score = model.evaluate([X_images_val_reshaped , X_tabular_prepared_val], y_val, verbose=1)\ntest_score = model.evaluate([X_images_test_reshaped , X_tabular_prepared_test], y_test, verbose=1)\n\nprint(\"\\nFinal Results:\")\nprint(f\"Train Accuracy: {train_score[1]*100:.2f}%\")\nprint(f\"Validation Accuracy: {val_score[1]*100:.2f}%\")\nprint(f\"Test Accuracy: {test_score[1]*100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T15:12:04.063056Z","iopub.execute_input":"2024-12-27T15:12:04.063359Z","iopub.status.idle":"2024-12-27T15:12:08.134146Z","shell.execute_reply.started":"2024-12-27T15:12:04.063337Z","shell.execute_reply":"2024-12-27T15:12:08.133395Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# show loss & accuracy plot\nplt.figure(figsize=(12, 4))\n\n# Display the loss curve over the epochs.\nplt.subplot(1, 2, 1)   # Creating the first subplot\nplt.plot(history.history['loss'], label='Train Loss')   # Plotting the training loss\nplt.plot(history.history['val_loss'], label='Validation Loss')    # Plotting the validation loss\nplt.title('Model Loss')     # Adding a title to the loss plot\nplt.xlabel('Epoch')      # Label for the x-axis (epochs)\nplt.ylabel('Loss')       # Label for the y-axis (loss value)\nplt.legend()           # Displaying the legend to differentiate the curves\n\n# Display the accuracy curve over the epochs.\nplt.subplot(1, 2, 2)      # Creating the second subplot\nplt.plot(history.history['accuracy'], label='Train Accuracy')     # Plotting the training accuracy\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')    # Plotting the validation accuracy\nplt.title('Model Accuracy')     # Adding a title to the accuracy plot\nplt.xlabel('Epoch')         # Label for the x-axis (epochs)\nplt.ylabel('Accuracy')      # Label for the y-axis (accuracy percentage)\nplt.legend()        # Displaying the legend to differentiate the curves\n\n# Adjusting the layout to ensure that the subplots do not overlap and are well-spaced.\nplt.tight_layout()\nplt.show()     # Displaying the plots.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T15:12:20.13455Z","iopub.execute_input":"2024-12-27T15:12:20.134918Z","iopub.status.idle":"2024-12-27T15:12:20.671202Z","shell.execute_reply.started":"2024-12-27T15:12:20.13489Z","shell.execute_reply":"2024-12-27T15:12:20.670357Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# save the model\nmodel.save('truetrue_model.h5')  # Save the model in HDF5 format\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T15:12:43.388921Z","iopub.execute_input":"2024-12-27T15:12:43.389235Z","iopub.status.idle":"2024-12-27T15:12:43.44409Z","shell.execute_reply.started":"2024-12-27T15:12:43.389211Z","shell.execute_reply":"2024-12-27T15:12:43.443225Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Path to the saved model\nmodel_path = \"/kaggle/input/truetrue/tensorflow2/default/1/truetrue_model.h5\"\n\n# Load the model\nmodel = load_model(model_path)\n\n# Example prediction\npredictions = model.predict([X_images_test_reshaped , X_tabular_prepared_test])\npred_labels = np.argmax(predictions, axis=1)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:44:37.625373Z","iopub.execute_input":"2024-12-27T21:44:37.625719Z","iopub.status.idle":"2024-12-27T21:44:41.120137Z","shell.execute_reply.started":"2024-12-27T21:44:37.625691Z","shell.execute_reply":"2024-12-27T21:44:41.119419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print classification report\nprint(classification_report(y_test, pred_labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:45:03.385329Z","iopub.execute_input":"2024-12-27T21:45:03.385691Z","iopub.status.idle":"2024-12-27T21:45:03.399823Z","shell.execute_reply.started":"2024-12-27T21:45:03.385661Z","shell.execute_reply":"2024-12-27T21:45:03.399044Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# show confusion matrix\nbeige_brown_palette = [\"#D2B48C\", \"#C2B280\", \"#8B4513\", \"#6F4F28\", \"#3E2B1B\"]\n\n# Generating the confusion matrix by comparing the true labels (y_test) and the predicted labels (pred_labels).\ncm = confusion_matrix(y_test, pred_labels)\n\n# Defining a custom colormap using the previously defined beige and brown color palette.\ncmap = ListedColormap(beige_brown_palette) \n\n# Creating the confusion matrix heatmap That is customized with the following properties:\n# annot=True: displays the numbers inside the heatmap cells.\n# fmt=\"d\": formats the annotations as integers.\n# cmap=beige_brown_palette: applies the custom color palette.\n# cbar=False: removes the color bar.\n# 'xticklabels' and 'yticklabels': set the x and y axis labels to the class labels.\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap=cmap, cbar=False, \n            xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:46:11.259843Z","iopub.execute_input":"2024-12-27T21:46:11.260146Z","iopub.status.idle":"2024-12-27T21:46:11.468123Z","shell.execute_reply.started":"2024-12-27T21:46:11.260125Z","shell.execute_reply":"2024-12-27T21:46:11.466795Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Precision:**\nprecision measure the accuracy of positive predictions.it tells us, of all the cases the model predicted as positive, how many are actualy positive\n\n**Recall:**\nRecall measures how well the model detects positive cases. It tells us, of all the actual positive cases, how many were correctly predicted by the model.\n\n**F1_Score:**\nF1-Score is the harmonic mean of precision and recall. It is a balanced metric that considers both precision and recall.","metadata":{}},{"cell_type":"code","source":"# Define a color palette using a list of color codes, which will be used to color the bars in the plots.\nbeige_brown_palette = [\"#D2B48C\", \"#C2B280\", \"#8B4513\", \"#6F4F28\", \"#3E2B1B\"]\n\n# Extract the unique class labels from the 'dx' column of the DataFrame.\nclass_labels = df['dx'].unique()\n\n# Calculate precision, recall, and F1-score for each class using the true and predicted labels.\n# The 'average=None' argument to return scores for each class separately.\nprecision = precision_score(y_test, pred_labels, average=None)\nrecall = recall_score(y_test, pred_labels, average=None)\nf1 = f1_score(y_test, pred_labels, average=None)\n\n# Create a 2x2 grid of subplots to visualize the performance metrics.\n# The figsize argument controls the size of the figure.\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n# Plot the precision scores for each class.\naxes[0, 0].bar(class_labels, precision, color=beige_brown_palette[:len(class_labels)])\naxes[0, 0].set_title('Precision')\naxes[0, 0].set_ylabel('Precision Score')\naxes[0, 0].tick_params(axis='x', rotation=45)\n\n# Plot the recall scores for each class.\naxes[0, 1].bar(class_labels, recall, color=beige_brown_palette[:len(class_labels)])\naxes[0, 1].set_title('Recall')\naxes[0, 1].set_ylabel('Recall Score')\naxes[0, 1].tick_params(axis='x', rotation=45)\n\n# Plot the F1-scores for each class.\naxes[1, 0].bar(class_labels, f1, color=beige_brown_palette[:len(class_labels)])\naxes[1, 0].set_title('F1-Score')\naxes[1, 0].set_ylabel('F1-Score')\naxes[1, 0].tick_params(axis='x', rotation=45)\n\n# Hide the last subplot (bottom-right corner).\naxes[1, 1].axis('off')\n\n# Adjust the layout to ensure proper spacing between plots.\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T21:48:31.765216Z","iopub.execute_input":"2024-12-27T21:48:31.765624Z","iopub.status.idle":"2024-12-27T21:48:32.6754Z","shell.execute_reply.started":"2024-12-27T21:48:31.76559Z","shell.execute_reply":"2024-12-27T21:48:32.674498Z"}},"outputs":[],"execution_count":null}]}